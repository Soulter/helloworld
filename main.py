import re
import json
import os
import uuid
import aiohttp
import asyncio
from datetime import datetime
from typing import Dict, List, Optional
from astrbot.api.event import filter, AstrMessageEvent
from astrbot.api.star import Context, Star, register
from astrbot.api import logger, AstrBotConfig
import astrbot.api.message_components as Comp




# è®¢é˜…æ•°æ®å­˜å‚¨è·¯å¾„
SUBSCRIPTION_FILE = "data/astrbot_plugin_github_sub_subscriptions.json"
# é»˜è®¤ä»“åº“æ•°æ®å­˜å‚¨è·¯å¾„
DEFAULT_REPO_FILE = "data/astrbot_plugin_github_sub_default_repos.json"

GITHUB_URL_PATTERN = r"https://github\.com/[\w\-]+/[\w\-]+(?:/(pull|issues)/\d+)?"
GITHUB_REPO_OPENGRAPH = "https://opengraph.githubassets.com/{hash}/{appendix}"
GITHUB_API_URL = "https://api.github.com/repos/{repo}"
GITHUB_ISSUES_API_URL = "https://api.github.com/repos/{repo}/issues"
GITHUB_RELEASES_API_URL = "https://api.github.com/repos/{repo}/releases"  # æ–°å¢Release API


@register(
    "astrbot_plugin_github_sub",
    "XieMu",
    "GitHubä»“åº“è®¢é˜…æ’ä»¶",
    "1.1.0",  # ç‰ˆæœ¬å·å‡çº§
    "https://github.com/xiemu-c/astrbot_plugin_github_sub",
)
class MyPlugin(Star):
    def __init__(self, context: Context, config: AstrBotConfig = None):
        super().__init__(context)
        self.config = config or {}
        self.subscriptions = self._load_subscriptions()
        self.default_repos = self._load_default_repos()
        # ä¿®æ”¹ï¼šåŒºåˆ†issueså’Œreleasesçš„æ£€æŸ¥æ—¶é—´
        self.last_check_time = {
            "issues": {},    # è®°å½•Issue/PRçš„æœ€åæ£€æŸ¥æ—¶é—´
            "releases": {}   # è®°å½•Releaseçš„æœ€åæ£€æŸ¥æ—¶é—´
        }
        self.use_lowercase = self.config.get("use_lowercase_repo", True)
        self.github_token = self.config.get("github_token", "")
        self.check_interval = self.config.get("check_interval", 30)
        # æ–°å¢ï¼šæ˜¯å¦åŒ…å«é¢„å‘å¸ƒç‰ˆæœ¬çš„é…ç½®
        self.include_prereleases = self.config.get("include_prereleases", False)

        # å¯åŠ¨åå°æ£€æŸ¥æ›´æ–°ä»»åŠ¡
        self.task = asyncio.create_task(self._check_updates_periodically())
        logger.info(
            f"GitHub è®¢é˜…æ’ä»¶åˆå§‹åŒ–å®Œæˆï¼Œæ£€æŸ¥é—´éš”: {self.check_interval}åˆ†é’Ÿï¼Œ"
            f"æ˜¯å¦åŒ…å«é¢„å‘å¸ƒç‰ˆæœ¬: {self.include_prereleases}"
        )

    def _load_subscriptions(self) -> Dict[str, List[str]]:
        """ä»JSONæ–‡ä»¶åŠ è½½è®¢é˜…æ•°æ®"""
        if os.path.exists(SUBSCRIPTION_FILE):
            try:
                with open(SUBSCRIPTION_FILE, "r", encoding="utf-8") as f:
                    return json.load(f)
            except Exception as e:
                logger.error(f"åŠ è½½è®¢é˜…æ•°æ®å¤±è´¥: {e}")
        return {}

    def _save_subscriptions(self):
        """å°†è®¢é˜…æ•°æ®ä¿å­˜åˆ°JSONæ–‡ä»¶"""
        try:
            os.makedirs(os.path.dirname(SUBSCRIPTION_FILE), exist_ok=True)
            with open(SUBSCRIPTION_FILE, "w", encoding="utf-8") as f:
                json.dump(self.subscriptions, f, ensure_ascii=False, indent=2)
        except Exception as e:
            logger.error(f"ä¿å­˜è®¢é˜…æ•°æ®å¤±è´¥: {e}")

    def _load_default_repos(self) -> Dict[str, str]:
        """ä»JSONæ–‡ä»¶åŠ è½½é»˜è®¤ä»“åº“è®¾ç½®"""
        if os.path.exists(DEFAULT_REPO_FILE):
            try:
                with open(DEFAULT_REPO_FILE, "r", encoding="utf-8") as f:
                    return json.load(f)
            except Exception as e:
                logger.error(f"åŠ è½½é»˜è®¤ä»“åº“æ•°æ®å¤±è´¥: {e}")
        return {}

    def _save_default_repos(self):
        """å°†é»˜è®¤ä»“åº“è®¾ç½®ä¿å­˜åˆ°JSONæ–‡ä»¶"""
        try:
            os.makedirs(os.path.dirname(DEFAULT_REPO_FILE), exist_ok=True)
            with open(DEFAULT_REPO_FILE, "w", encoding="utf-8") as f:
                json.dump(self.default_repos, f, ensure_ascii=False, indent=2)
        except Exception as e:
            logger.error(f"ä¿å­˜é»˜è®¤ä»“åº“æ•°æ®å¤±è´¥: {e}")

    def _normalize_repo_name(self, repo: str) -> str:
        """æ ¹æ®é…ç½®æ ‡å‡†åŒ–ä»“åº“åç§°"""
        return repo.lower() if self.use_lowercase else repo

    def _get_github_headers(self) -> Dict[str, str]:
        """è·å–å¸¦æœ‰tokenï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰çš„GitHub APIè¯·æ±‚å¤´"""
        headers = {"Accept": "application/vnd.github.v3+json"}
        if self.github_token:
            headers["Authorization"] = f"token {self.github_token}"
        return headers

    @filter.regex(GITHUB_URL_PATTERN)
    async def github_repo(self, event: AstrMessageEvent):
        """è§£æ Github ä»“åº“ä¿¡æ¯"""
        msg = event.message_str
        match = re.search(GITHUB_URL_PATTERN, msg)
        repo_url = match.group(0)
        repo_url = repo_url.replace("https://github.com/", "")
        hash_value = uuid.uuid4().hex
        opengraph_url = GITHUB_REPO_OPENGRAPH.format(hash=hash_value, appendix=repo_url)
        logger.info(f"ç”Ÿæˆçš„ OpenGraph URL: {opengraph_url}")

        try:
            yield event.image_result(opengraph_url)
        except Exception as e:
            logger.error(f"ä¸‹è½½å›¾ç‰‡å¤±è´¥: {e}")
            yield event.plain_result("ä¸‹è½½ GitHub å›¾ç‰‡å¤±è´¥: " + str(e))
            return

    @filter.command("ghsub")
    async def subscribe_repo(self, event: AstrMessageEvent, repo: str):
        """è®¢é˜…GitHubä»“åº“çš„Issueã€PRå’ŒReleaseã€‚ä¾‹å¦‚: /ghsub Soulter/AstrBot"""
        if not self._is_valid_repo(repo):
            yield event.plain_result("è¯·æä¾›æœ‰æ•ˆçš„ä»“åº“åï¼Œæ ¼å¼ä¸º: ç”¨æˆ·å/ä»“åº“å")
            return

        # æ ‡å‡†åŒ–ä»“åº“åç§°
        normalized_repo = self._normalize_repo_name(repo)

        # æ£€æŸ¥ä»“åº“æ˜¯å¦å­˜åœ¨
        try:
            async with aiohttp.ClientSession() as session:
                async with session.get(
                    GITHUB_API_URL.format(repo=repo), headers=self._get_github_headers()
                ) as resp:
                    if resp.status != 200:
                        yield event.plain_result(f"ä»“åº“ {repo} ä¸å­˜åœ¨æˆ–æ— æ³•è®¿é—®")
                        return

                    repo_data = await resp.json()
                    display_name = repo_data.get("full_name", repo)
        except Exception as e:
            logger.error(f"è®¿é—®GitHub APIå¤±è´¥: {e}")
            yield event.plain_result(f"æ£€æŸ¥ä»“åº“æ—¶å‡ºé”™: {str(e)}")
            return

        # è·å–è®¢é˜…è€…å”¯ä¸€æ ‡è¯†
        subscriber_id = event.unified_msg_origin

        # æ·»åŠ æˆ–æ›´æ–°è®¢é˜…
        if normalized_repo not in self.subscriptions:
            self.subscriptions[repo] = []

        if subscriber_id not in self.subscriptions[repo]:
            self.subscriptions[repo].append(subscriber_id)
            self._save_subscriptions()

            # ä¸ºæ–°è®¢é˜…è·å–åˆå§‹çŠ¶æ€
            await self._fetch_new_items(repo, None)
            await self._fetch_new_releases(repo, None)  # åˆå§‹åŒ–Releaseæ£€æŸ¥æ—¶é—´

            yield event.plain_result(f"æˆåŠŸè®¢é˜…ä»“åº“ {display_name} çš„Issueã€PRå’ŒReleaseæ›´æ–°")
        else:
            yield event.plain_result(f"ä½ å·²ç»è®¢é˜…äº†ä»“åº“ {display_name}")

        # è®¾ç½®ä¸ºå½“å‰ä¼šè¯çš„é»˜è®¤ä»“åº“
        self.default_repos[event.unified_msg_origin] = repo
        self._save_default_repos()

    @filter.command("ghunsub")
    async def unsubscribe_repo(self, event: AstrMessageEvent, repo: str = None):
        """å–æ¶ˆè®¢é˜…GitHubä»“åº“ã€‚ä¾‹å¦‚: /ghunsub Soulter/AstrBotï¼Œä¸æä¾›ä»“åº“ååˆ™å–æ¶ˆæ‰€æœ‰è®¢é˜…"""
        subscriber_id = event.unified_msg_origin

        if repo is None:
            # å–æ¶ˆæ‰€æœ‰è®¢é˜…
            unsubscribed = []
            for repo_name, subscribers in list(self.subscriptions.items()):
                if subscriber_id in subscribers:
                    subscribers.remove(subscriber_id)
                    unsubscribed.append(repo_name)
                    if not subscribers:
                        del self.subscriptions[repo_name]
                        # ç§»é™¤æ£€æŸ¥æ—¶é—´è®°å½•
                        if repo_name in self.last_check_time["issues"]:
                            del self.last_check_time["issues"][repo_name]
                        if repo_name in self.last_check_time["releases"]:
                            del self.last_check_time["releases"][repo_name]

            if unsubscribed:
                self._save_subscriptions()
                yield event.plain_result(
                    f"å·²å–æ¶ˆè®¢é˜…æ‰€æœ‰ä»“åº“: {', '.join(unsubscribed)}"
                )
            else:
                yield event.plain_result("ä½ æ²¡æœ‰è®¢é˜…ä»»ä½•ä»“åº“")
            return

        if not self._is_valid_repo(repo):
            yield event.plain_result("è¯·æä¾›æœ‰æ•ˆçš„ä»“åº“åï¼Œæ ¼å¼ä¸º: ç”¨æˆ·å/ä»“åº“å")
            return

        # æ ‡å‡†åŒ–ä»“åº“åç§°
        normalized_repo = self._normalize_repo_name(repo)

        # å¦‚æœä½¿ç”¨å°å†™ï¼Œåˆ™ä¸åŒºåˆ†å¤§å°å†™æŸ¥æ‰¾ä»“åº“
        if self.use_lowercase:
            matched_repos = [
                r for r in self.subscriptions.keys() if r.lower() == normalized_repo
            ]
            if matched_repos:
                normalized_repo = matched_repos[0]

        if (
            normalized_repo in self.subscriptions
            and subscriber_id in self.subscriptions[normalized_repo]
        ):
            self.subscriptions[normalized_repo].remove(subscriber_id)
            if not self.subscriptions[normalized_repo]:
                del self.subscriptions[normalized_repo]
                if normalized_repo in self.last_check_time["issues"]:
                    del self.last_check_time["issues"][normalized_repo]
                if normalized_repo in self.last_check_time["releases"]:
                    del self.last_check_time["releases"][normalized_repo]
            self._save_subscriptions()
            yield event.plain_result(f"å·²å–æ¶ˆè®¢é˜…ä»“åº“ {repo}")
        else:
            yield event.plain_result(f"ä½ æ²¡æœ‰è®¢é˜…ä»“åº“ {repo}")

    @filter.command("ghlist")
    async def list_subscriptions(self, event: AstrMessageEvent):
        """åˆ—å‡ºå½“å‰è®¢é˜…çš„GitHubä»“åº“"""
        subscriber_id = event.unified_msg_origin
        subscribed_repos = []

        for repo, subscribers in self.subscriptions.items():
            if subscriber_id in subscribers:
                subscribed_repos.append(repo)

        if subscribed_repos:
            yield event.plain_result(
                f"ä½ å½“å‰è®¢é˜…çš„ä»“åº“æœ‰: {', '.join(subscribed_repos)}"
            )
        else:
            yield event.plain_result("ä½ å½“å‰æ²¡æœ‰è®¢é˜…ä»»ä½•ä»“åº“")

    def _is_valid_repo(self, repo: str) -> bool:
        """æ£€æŸ¥ä»“åº“åç§°æ˜¯å¦æœ‰æ•ˆ"""
        return bool(re.match(r"[\w\-]+/[\w\-]+$", repo))

    async def _check_updates_periodically(self):
        """å®šæœŸæ£€æŸ¥è®¢é˜…ä»“åº“çš„æ›´æ–°"""
        try:
            while True:
                try:
                    await self._check_all_repos()
                except Exception as e:
                    logger.error(f"æ£€æŸ¥ä»“åº“æ›´æ–°æ—¶å‡ºé”™: {e}")

                # ä½¿ç”¨é…ç½®çš„æ£€æŸ¥é—´éš”
                minutes = max(1, self.check_interval)  # ç¡®ä¿è‡³å°‘1åˆ†é’Ÿ
                logger.debug(f"ç­‰å¾… {minutes} åˆ†é’Ÿåå†æ¬¡æ£€æŸ¥ä»“åº“æ›´æ–°")
                await asyncio.sleep(minutes * 60)
        except asyncio.CancelledError:
            logger.info("åœæ­¢æ£€æŸ¥ä»“åº“æ›´æ–°")

    async def _check_all_repos(self):
        """æ£€æŸ¥æ‰€æœ‰è®¢é˜…ä»“åº“çš„æ›´æ–°"""
        for repo in list(self.subscriptions.keys()):
            logger.info(f"æ­£åœ¨æ£€æŸ¥ä»“åº“ {repo} æ›´æ–°")
            if not self.subscriptions[repo]:  # å¦‚æœæ²¡æœ‰è®¢é˜…è€…åˆ™è·³è¿‡
                continue

            try:
                # æ£€æŸ¥æ–°çš„issueså’ŒPRs
                issue_last_check = self.last_check_time["issues"].get(repo, None)
                new_items = await self._fetch_new_items(repo, issue_last_check)
                if new_items:
                    self.last_check_time["issues"][repo] = datetime.utcnow().replace(microsecond=0).isoformat()
                    await self._notify_subscribers(repo, new_items)

                # æ£€æŸ¥æ–°çš„Releases
                release_last_check = self.last_check_time["releases"].get(repo, None)
                new_releases = await self._fetch_new_releases(repo, release_last_check)
                if new_releases:
                    self.last_check_time["releases"][repo] = datetime.utcnow().replace(microsecond=0).isoformat()
                    await self._notify_subscribers_releases(repo, new_releases)

            except Exception as e:
                logger.error(f"æ£€æŸ¥ä»“åº“ {repo} æ›´æ–°æ—¶å‡ºé”™: {e}")

    async def _fetch_new_items(self, repo: str, last_check: str):
        """ä»ä¸Šæ¬¡æ£€æŸ¥ä»¥æ¥è·å–ä»“åº“çš„æ–°issueså’ŒPRs"""
        if not last_check:
            # å¦‚æœæ˜¯ç¬¬ä¸€æ¬¡æ£€æŸ¥ï¼Œåªè®°å½•å½“å‰æ—¶é—´å¹¶è¿”å›ç©ºåˆ—è¡¨
            self.last_check_time["issues"][repo] = (
                datetime.utcnow().replace(microsecond=0).isoformat()
            )
            logger.info(f"åˆå§‹åŒ–ä»“åº“ {repo} çš„Issue/PRæ—¶é—´æˆ³: {self.last_check_time['issues'][repo]}")
            return []

        try:
            last_check_dt = datetime.fromisoformat(last_check)
            if hasattr(last_check_dt, "tzinfo") and last_check_dt.tzinfo is not None:
                last_check_dt = last_check_dt.replace(tzinfo=None)

            logger.info(f"ä»“åº“ {repo} çš„Issue/PRä¸Šæ¬¡æ£€æŸ¥æ—¶é—´: {last_check_dt.isoformat()}")
            new_items = []

            async with aiohttp.ClientSession() as session:
                try:
                    params = {
                        "sort": "created",
                        "direction": "desc",
                        "state": "all",
                        "per_page": 10,
                    }
                    async with session.get(
                        GITHUB_ISSUES_API_URL.format(repo=repo),
                        params=params,
                        headers=self._get_github_headers(),
                    ) as resp:
                        if resp.status == 200:
                            items = await resp.json()

                            for item in items:
                                github_timestamp = item["created_at"].replace("Z", "")
                                created_at = datetime.fromisoformat(github_timestamp)
                                created_at = created_at.replace(tzinfo=None)

                                if created_at > last_check_dt:
                                    logger.info(f"å‘ç°æ–°çš„item #{item['number']} in {repo}")
                                    new_items.append(item)
                                else:
                                    break
                        else:
                            logger.error(f"è·å–ä»“åº“ {repo} çš„Issue/PRå¤±è´¥: {resp.status}: {await resp.text()}")
                except Exception as e:
                    logger.error(f"è·å–ä»“åº“ {repo} çš„Issue/PRæ—¶å‡ºé”™: {e}")

            self.last_check_time["issues"][repo] = (
                datetime.utcnow().replace(microsecond=0).isoformat()
            )
            logger.info(f"æ›´æ–°ä»“åº“ {repo} çš„Issue/PRæ—¶é—´æˆ³ä¸º: {self.last_check_time['issues'][repo]}")

            return new_items
        except Exception as e:
            logger.error(f"è§£æIssue/PRæ—¶é—´æ—¶å‡ºé”™: {e}")
            self.last_check_time["issues"][repo] = (
                datetime.utcnow().replace(microsecond=0).isoformat()
            )
            logger.info(f"å‡ºé”™åæ›´æ–°ä»“åº“ {repo} çš„Issue/PRæ—¶é—´æˆ³ä¸º: {self.last_check_time['issues'][repo]}")
            return []

    # æ–°å¢ï¼šè·å–æ–°çš„Releases
    async def _fetch_new_releases(self, repo: str, last_check: str):
        """ä»ä¸Šæ¬¡æ£€æŸ¥ä»¥æ¥è·å–ä»“åº“çš„æ–°Releases"""
        if not last_check:
            # ç¬¬ä¸€æ¬¡æ£€æŸ¥ï¼Œåˆå§‹åŒ–æ—¶é—´æˆ³
            self.last_check_time["releases"][repo] = (
                datetime.utcnow().replace(microsecond=0).isoformat()
            )
            logger.info(f"åˆå§‹åŒ–ä»“åº“ {repo} çš„Releaseæ—¶é—´æˆ³: {self.last_check_time['releases'][repo]}")
            return []

        try:
            last_check_dt = datetime.fromisoformat(last_check)
            if hasattr(last_check_dt, "tzinfo") and last_check_dt.tzinfo is not None:
                last_check_dt = last_check_dt.replace(tzinfo=None)

            logger.info(f"ä»“åº“ {repo} çš„Releaseä¸Šæ¬¡æ£€æŸ¥æ—¶é—´: {last_check_dt.isoformat()}")
            new_releases = []

            async with aiohttp.ClientSession() as session:
                try:
                    params = {
                        "sort": "published",
                        "direction": "desc",
                        "per_page": 10,
                    }
                    async with session.get(
                        GITHUB_RELEASES_API_URL.format(repo=repo),
                        params=params,
                        headers=self._get_github_headers(),
                    ) as resp:
                        if resp.status == 200:
                            releases = await resp.json()

                            for release in releases:
                                # è·³è¿‡è‰ç¨¿ç‰ˆæœ¬
                                if release["draft"]:
                                    continue
                                    
                                # æ ¹æ®é…ç½®å†³å®šæ˜¯å¦è·³è¿‡é¢„å‘å¸ƒç‰ˆæœ¬
                                if not self.include_prereleases and release["prerelease"]:
                                    continue

                                # è§£æå‘å¸ƒæ—¶é—´
                                publish_timestamp = release["published_at"].replace("Z", "") if release["published_at"] else None
                                if not publish_timestamp:
                                    continue  # è·³è¿‡æœªå‘å¸ƒçš„ç‰ˆæœ¬
                                    
                                published_at = datetime.fromisoformat(publish_timestamp)
                                published_at = published_at.replace(tzinfo=None)

                                if published_at > last_check_dt:
                                    logger.info(f"å‘ç°æ–°çš„Release {release['tag_name']} in {repo}")
                                    new_releases.append(release)
                                else:
                                    break  # æŒ‰æ—¶é—´æ’åºï¼Œå¯æå‰ä¸­æ–­
                        else:
                            logger.error(f"è·å–ä»“åº“ {repo} çš„Releaseå¤±è´¥: {resp.status}: {await resp.text()}")
                except Exception as e:
                    logger.error(f"è·å–ä»“åº“ {repo} çš„Releaseæ—¶å‡ºé”™: {e}")

            self.last_check_time["releases"][repo] = (
                datetime.utcnow().replace(microsecond=0).isoformat()
            )
            logger.info(f"æ›´æ–°ä»“åº“ {repo} çš„Releaseæ—¶é—´æˆ³ä¸º: {self.last_check_time['releases'][repo]}")

            return new_releases
        except Exception as e:
            logger.error(f"è§£æReleaseæ—¶é—´æ—¶å‡ºé”™: {e}")
            self.last_check_time["releases"][repo] = (
                datetime.utcnow().replace(microsecond=0).isoformat()
            )
            logger.info(f"å‡ºé”™åæ›´æ–°ä»“åº“ {repo} çš„Releaseæ—¶é—´æˆ³ä¸º: {self.last_check_time['releases'][repo]}")
            return []

    async def _notify_subscribers(self, repo: str, new_items: List[Dict]):
        """é€šçŸ¥è®¢é˜…è€…æœ‰å…³æ–°çš„issueså’ŒPRs"""
        if not new_items:
            return

        for subscriber_id in self.subscriptions.get(repo, []):
            try:
                for item in new_items:
                    item_type = "PR" if "pull_request" in item else "Issue"
                    message = (
                        f"[GitHubæ›´æ–°] ä»“åº“ {repo} æœ‰æ–°çš„{item_type}:\n"
                        f"#{item['number']} {item['title']}\n"
                        f"ä½œè€…: {item['user']['login']}\n"
                        f"é“¾æ¥: {item['html_url']}"
                    )

                    await self.context.send_message(
                        subscriber_id, Comp.Plain(message)
                    )
                    await asyncio.sleep(1)
            except Exception as e:
                logger.error(f"å‘è®¢é˜…è€… {subscriber_id} å‘é€é€šçŸ¥æ—¶å‡ºé”™: {e}")

    # æ–°å¢ï¼šé€šçŸ¥è®¢é˜…è€…æœ‰å…³æ–°çš„Releases
    async def _notify_subscribers_releases(self, repo: str, new_releases: List[Dict]):
        """é€šçŸ¥è®¢é˜…è€…æœ‰å…³æ–°çš„Release"""
        if not new_releases:
            return

        for subscriber_id in self.subscriptions.get(repo, []):
            try:
                for release in new_releases:
                    # å¤„ç†å‘å¸ƒè¯´æ˜ï¼ˆè¿‡é•¿æ—¶æˆªæ–­ï¼‰
                    body = release.get("body", "æ— å‘å¸ƒè¯´æ˜")
                    if len(body) > 200:
                        body = body[:200] + "..."
                    
                    # æ„å»ºé€šçŸ¥æ¶ˆæ¯
                    message_parts = [
                        f"[GitHub Releaseæ›´æ–°] ä»“åº“ {repo} å‘å¸ƒäº†æ–°ç‰ˆæœ¬:\n",
                        f"ç‰ˆæœ¬: {release['tag_name']}"
                    ]
                    
                    # å¦‚æœæ˜¯é¢„å‘å¸ƒç‰ˆæœ¬ï¼Œæ·»åŠ æ ‡è®°
                    if release["prerelease"]:
                        message_parts.append(" ğŸ§ª é¢„å‘å¸ƒ")
                        
                    message_parts.extend([
                        f"\næ ‡é¢˜: {release['name'] or 'æ— æ ‡é¢˜'}\n",
                        f"å‘å¸ƒæ—¶é—´: {release['published_at'].replace('T', ' ').replace('Z', '')}\n",
                        f"è¯´æ˜: {body}\n",
                        f"ä¸‹è½½: {release['html_url']}"
                    ])
                    
                    message = ''.join(message_parts)

                    # å‘é€é€šçŸ¥
                    await self.context.send_message(
                        subscriber_id, Comp.Plain(message)
                    )
                    await asyncio.sleep(1)
            except Exception as e:
                logger.error(f"å‘è®¢é˜…è€… {subscriber_id} å‘é€Releaseé€šçŸ¥æ—¶å‡ºé”™: {e}")

    async def terminate(self):
        """ç»ˆæ­¢å‰æ¸…ç†å¹¶ä¿å­˜æ•°æ®"""
        self._save_subscriptions()
        self._save_default_repos()
        self.task.cancel()
        logger.info("GitHub è®¢é˜…æ’ä»¶ å·²ç»ˆæ­¢")
